{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCjczpoOKalN"
   },
   "source": [
    "## Importing libraries and getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.394619Z",
     "start_time": "2025-04-28T17:23:34.264230Z"
    },
    "id": "8PSMUtsEE5bz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "    v2.Normalize(mean= (0.1307,), std =(0.3081,)),\n",
    "])\n",
    "\n",
    "# mean and std are calculated for MNIST dataset\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.410741Z",
     "start_time": "2025-04-28T17:23:34.403675Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "n40o6ux3MVw4",
    "outputId": "98a5dd1f-ba29-4b91-96f4-e96767087cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ4i-UdZKi6i"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.455194Z",
     "start_time": "2025-04-28T17:23:34.428724Z"
    },
    "id": "SRL3JTCrFitv"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    # conversion layers\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    # batch norm\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "    # maxpooling\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # fully conected layers\n",
    "    self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Conv -> BN -> ReLU -> Pool\n",
    "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y2mDaVmMtax"
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.554470Z",
     "start_time": "2025-04-28T17:23:34.548394Z"
    },
    "id": "g0B80fwpPOmU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlG8O7pvXAyO"
   },
   "source": [
    "## Functions for GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.607321Z",
     "start_time": "2025-04-28T17:23:34.601138Z"
    },
    "id": "m31rnGh3PliL"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_flat_params(model):\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.data.view(-1))\n",
    "    flat_params = torch.cat(params)\n",
    "    return flat_params.clone()\n",
    "\n",
    "def set_flat_params(model, flat_params):\n",
    "    pointer = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        param.data.copy_(flat_params[pointer:pointer + num_params].view_as(param))\n",
    "        pointer += num_params\n",
    "\n",
    "def create_random_model(base_model_class, device):\n",
    "    model = base_model_class().to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.data = torch.randn_like(param)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoK3fPNcXJbN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:23:34.639916Z",
     "start_time": "2025-04-28T17:23:34.633896Z"
    },
    "id": "RXCmfQaXXLk7"
   },
   "outputs": [],
   "source": [
    "# Create population of K CNN models (model = CNN().to(device)) with random param, evaluate each of them and sort from the best to worst(fitness)\n",
    "# Let the best Top_n stay (elitism), and create new population using crossover and mutation, and elitic top_n to new_population, evaluate ...(repeat for N generation)\n",
    "# and the best model that was made in the last gen is evaluated on test_loader(test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:35:01.299904Z",
     "start_time": "2025-04-28T17:30:22.455996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "Best Fitness: 16.293333333333333\n",
      "New population created\n",
      "Best Fitness in Generation 1: 16.293333333333333%\n",
      "Generation 2\n",
      "Best Fitness: 16.293333333333333\n",
      "New population created\n",
      "Best Fitness in Generation 2: 16.293333333333333%\n",
      "Final Test Accuracy: 16.54%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def fitness_function(model, data_loader):\n",
    "    return evaluate(model, data_loader)\n",
    "\n",
    "def selection(population, fitnesses, top_n=None):\n",
    "    if top_n is None:\n",
    "        top_n = len(population)\n",
    "    sorted_indices = sorted(range(len(fitnesses)), key=lambda i: fitnesses[i], reverse=True)\n",
    "    return [population[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child = copy.deepcopy(parent1)\n",
    "    flat_params1 = get_flat_params(parent1)\n",
    "    flat_params2 = get_flat_params(parent2)\n",
    "    crossover_point = random.randint(0, len(flat_params1))\n",
    "    new_params = torch.cat((flat_params1[:crossover_point], flat_params2[crossover_point:]))\n",
    "    set_flat_params(child, new_params)\n",
    "    return child\n",
    "\n",
    "def mutate(model, mutation_rate):\n",
    "    mutated_model = copy.deepcopy(model)\n",
    "    flat_params = get_flat_params(mutated_model)\n",
    "    for i in range(len(flat_params)):\n",
    "        if random.random() < mutation_rate:\n",
    "            flat_params[i] += torch.randn(1).item()\n",
    "    set_flat_params(mutated_model, flat_params)\n",
    "    return mutated_model\n",
    "\n",
    "population_size = 4\n",
    "top_n = 2\n",
    "mutation_rate = round(random.uniform(0.01, 1), 2)\n",
    "number_of_generations = 2\n",
    "\n",
    "population = [create_random_model(CNN, device) for _ in range(population_size)]\n",
    "best_model = None\n",
    "best_fitness = -float(\"inf\")\n",
    "\n",
    "for generation in range(number_of_generations):\n",
    "    print(f\"Generation {generation + 1}\")\n",
    "    fitnesses = [fitness_function(model, train_loader) for model in population]\n",
    "    elite = selection(population, fitnesses, top_n)\n",
    "    new_population = elite\n",
    "\n",
    "    while len(new_population) < population_size:\n",
    "        parent1, parent2 = random.sample(elite, 2)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child, mutation_rate)\n",
    "        new_population.append(child)\n",
    "\n",
    "    population = new_population\n",
    "    print(\"New population created\")\n",
    "\n",
    "    generation_best_fitness = max(fitnesses)\n",
    "    if generation_best_fitness > best_fitness:\n",
    "        best_fitness = generation_best_fitness\n",
    "        best_model = elite[0]\n",
    "\n",
    "    print(f\"Best Fitness in Generation {generation + 1}: {generation_best_fitness}%\")\n",
    "\n",
    "final_test_accuracy = fitness_function(best_model, test_loader)\n",
    "print(f\"Final Test Accuracy: {final_test_accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9y2mDaVmMtax",
    "xoK3fPNcXJbN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
